{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ YouTube Knowledge Base\n",
    "### Turn hours of video into instant answers\n",
    "\n",
    "---\n",
    "\n",
    "**The Problem:** You follow multiple YouTube channels on AI, programming, or any topic. Each posts 2-3 videos per week. That's 50+ hours of content per month. You can't watch it all, but you need specific answers buried in those videos.\n",
    "\n",
    "**The Solution:** This tool extracts transcripts from YouTube videos, chunks them semantically, and lets you search with natural language. Ask a question ‚Üí get an answer with a timestamped link to the exact moment in the video.\n",
    "\n",
    "---\n",
    "\n",
    "### What you'll see in this demo:\n",
    "1. **Ask questions** ‚Üí Get synthesized answers from your video library\n",
    "2. **Jump to source** ‚Üí Timestamped links to exact video moments\n",
    "3. **Organize content** ‚Üí Tags, collections, and personal notes\n",
    "\n",
    "Let's start! üëá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Just two cells to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment & imports (run once)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from youtube_knowledgebase_mcp import (\n",
    "    process_youtube_video, search_knowledge_base, get_status,\n",
    "    get_source, list_sources, add_tags, list_tags,\n",
    "    add_to_collection, list_collections, set_summary, get_summary,\n",
    ")\n",
    "\n",
    "client = OpenAI()\n",
    "print(\"‚úÖ Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's in the knowledge base\n",
    "status = get_status()\n",
    "print(f\"üìö Knowledge Base: {status.total_sources} videos, {status.total_chunks} searchable chunks\")\n",
    "\n",
    "if status.total_sources == 0:\n",
    "    print(\"\\n‚ö†Ô∏è  Empty! Let's add a video in the next section.\")\n",
    "else:\n",
    "    print(\"\\nüì∫ Videos loaded:\")\n",
    "    for src in list_sources(limit=5):\n",
    "        print(f\"   ‚Ä¢ {src.title[:60]}{'...' if len(src.title) > 60 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add a Video (Optional)\n",
    "\n",
    "Skip this if you already have videos loaded. Processing takes ~30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a video to the knowledge base\n",
    "# This video covers 6 context engineering techniques for LLM agents\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=nyKvyRrpbyY\"\n",
    "\n",
    "print(f\"Processing: {VIDEO_URL}\")\n",
    "print(\"(This may take 30-60 seconds...)\\n\")\n",
    "\n",
    "result = await process_youtube_video(VIDEO_URL)\n",
    "\n",
    "if result.success:\n",
    "    print(f\"‚úÖ Added: {result.title}\")\n",
    "    print(f\"   Created {result.chunk_count} searchable chunks\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. üîç Ask Questions (The Main Event)\n",
    "\n",
    "This is where the magic happens. Ask natural language questions and get:\n",
    "- **Synthesized answers** from video transcripts\n",
    "- **Timestamped links** to jump directly to the relevant part\n",
    "\n",
    "**Try it:** Change the question below and re-run the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask(question: str, num_sources: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Ask a question and get an answer from your video knowledge base.\n",
    "    \n",
    "    This is the complete RAG pipeline:\n",
    "    1. Search for relevant video chunks\n",
    "    2. Use LLM to synthesize an answer\n",
    "    3. Show timestamped source links\n",
    "    \"\"\"\n",
    "    # Retrieve relevant chunks\n",
    "    results = await search_knowledge_base(question, limit=num_sources)\n",
    "    \n",
    "    if results.total_results == 0:\n",
    "        print(\"No relevant content found. Try adding more videos!\")\n",
    "        return\n",
    "    \n",
    "    # Build context from chunks\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"[{i+1}] {r.chunk.content}\" \n",
    "        for i, r in enumerate(results.results)\n",
    "    )\n",
    "    \n",
    "    # Generate answer with LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Answer based ONLY on the provided video transcript excerpts. Be concise but comprehensive. If the context doesn't have enough info, say so.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {question}\"}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=400\n",
    "    )\n",
    "    \n",
    "    # Display answer\n",
    "    print(f\"üí° {response.choices[0].message.content}\")\n",
    "    \n",
    "    # Show sources with timestamps\n",
    "    print(\"\\nüìç Sources:\")\n",
    "    seen = set()\n",
    "    for r in results.results:\n",
    "        if r.timestamp_link and r.timestamp_link not in seen:\n",
    "            seen.add(r.timestamp_link)\n",
    "            print(f\"   {r.timestamp_link}\")\n",
    "\n",
    "print(\"‚úÖ ask() function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ TRY IT: Change this question and re-run!\n",
    "\n",
    "await ask(\"What is context quarantine and why is it useful for AI agents?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More example questions to try:\n",
    "\n",
    "await ask(\"How can I implement RAG for my agent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ask(\"What is context offloading and how does it help with memory?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. üìä Explore Your Library\n",
    "\n",
    "See what's in your knowledge base and search by topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all videos with their metadata\n",
    "print(\"üì∫ Your Video Library:\\n\")\n",
    "\n",
    "for source in list_sources():\n",
    "    tags = f\" [{', '.join(source.tags)}]\" if source.tags else \"\"\n",
    "    print(f\"‚Ä¢ {source.title}\")\n",
    "    print(f\"  Channel: {source.channel} | Chunks: {source.chunk_count}{tags}\")\n",
    "    print(f\"  {source.url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick search (retrieval only, no LLM)\n",
    "query = \"system prompt\"\n",
    "\n",
    "results = await search_knowledge_base(query, limit=3)\n",
    "print(f\"üîç Search: '{query}'\\n\")\n",
    "\n",
    "for i, r in enumerate(results.results, 1):\n",
    "    print(f\"[{i}] {r.timestamp_link}\")\n",
    "    print(f\"    {r.chunk.content[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. üè∑Ô∏è Organize with Tags & Collections\n",
    "\n",
    "As your library grows, organize videos for easy filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a video to organize\n",
    "sources = list_sources(limit=1)\n",
    "if sources:\n",
    "    video = sources[0]\n",
    "    video_id = video.source_id\n",
    "    \n",
    "    # Add tags\n",
    "    add_tags(video_id, [\"agents\", \"context-engineering\", \"langchain\"])\n",
    "    \n",
    "    # Add to collections\n",
    "    add_to_collection(video_id, \"AI Engineering\")\n",
    "    add_to_collection(video_id, \"Must Review\")\n",
    "    \n",
    "    print(f\"‚úÖ Organized: {video.title[:50]}...\")\n",
    "    print(f\"   Tags: {list_tags()}\")\n",
    "    print(f\"   Collections: {list_collections()}\")\n",
    "else:\n",
    "    print(\"No videos to organize. Add one first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by tag or collection\n",
    "print(\"Videos tagged 'agents':\")\n",
    "for v in list_sources(tags=[\"agents\"]):\n",
    "    print(f\"  ‚Ä¢ {v.title}\")\n",
    "\n",
    "print(\"\\nVideos in 'Must Review' collection:\")\n",
    "for v in list_sources(collections=[\"Must Review\"]):\n",
    "    print(f\"  ‚Ä¢ {v.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. üìù Add Your Notes\n",
    "\n",
    "Add personal summaries or key takeaways to any video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a summary to the video\n",
    "sources = list_sources(limit=1)\n",
    "if sources:\n",
    "    video_id = sources[0].source_id\n",
    "    \n",
    "    my_notes = \"\"\"\n",
    "Key Takeaways:\n",
    "‚Ä¢ Context engineering = filling the context window with the RIGHT info at each step\n",
    "‚Ä¢ 6 techniques: system prompt, few-shot, RAG, tool feedback, offloading, quarantine\n",
    "‚Ä¢ Context quarantine: use sub-agents to isolate different topics\n",
    "‚Ä¢ Don't underestimate the power of a good system prompt!\n",
    "\"\"\"\n",
    "    \n",
    "    set_summary(video_id, my_notes.strip())\n",
    "    print(\"‚úÖ Summary saved!\\n\")\n",
    "    print(get_summary(video_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "### Use with Claude Desktop\n",
    "This is an MCP (Model Context Protocol) server. Connect it to Claude Desktop for a conversational AI interface to your video library.\n",
    "\n",
    "```json\n",
    "// claude_desktop_config.json\n",
    "{\n",
    "  \"mcpServers\": {\n",
    "    \"youtube-kb\": {\n",
    "      \"command\": \"uv\",\n",
    "      \"args\": [\"--directory\", \"/path/to/youtube-knowledge-base-mcp\", \"run\", \"youtube-kb\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Build Your Library\n",
    "```python\n",
    "# Add more videos\n",
    "videos = [\n",
    "    \"https://www.youtube.com/watch?v=...\",\n",
    "    \"https://www.youtube.com/watch?v=...\",\n",
    "]\n",
    "for url in videos:\n",
    "    await process_youtube_video(url)\n",
    "```\n",
    "\n",
    "### Ideas\n",
    "- Process all videos from your favorite AI channel\n",
    "- Create collections by skill level (Beginner, Advanced)\n",
    "- Tag videos by framework (LangChain, LlamaIndex, etc.)\n",
    "- Use for research: find relevant talks before writing a blog post"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
