{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Transcript Knowledge Base - Demo\n",
    "\n",
    "This notebook demonstrates the key functionality of the YouTube Transcript Knowledge Base project. It allows you to process YouTube videos, build a searchable knowledge base from their transcripts, organize videos into lists, and query the knowledge base for specific information.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, ensure you have the required dependencies installed and your OpenAI API key configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI API key found in environment variables\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import dotenv\n",
    "\n",
    "# Load environment variables from .env file (containing your OPENAI_API_KEY)\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Verify OpenAI API key is available\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    print(\"⚠️ OPENAI_API_KEY not found in environment variables.\")\n",
    "    print(\"Please create a .env file with your OpenAI API key or set it manually below:\")\n",
    "    # Uncomment and replace with your key if needed\n",
    "    # os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
    "else:\n",
    "    print(\"✅ OpenAI API key found in environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data Paths\n",
    "\n",
    "Set up paths for data storage and initialize the MCP tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be stored in: /Users/mk/Work/Agent_learning/data\n"
     ]
    }
   ],
   "source": [
    "# Define paths similar to main.py\n",
    "BASE_PATH = os.path.dirname(os.path.abspath(\".\"))\n",
    "DATA_FOLDER = os.path.join(BASE_PATH, \"data\")\n",
    "DATA_PATH = os.path.join(DATA_FOLDER, \"processed_data\")\n",
    "FAISS_INDEX_PATH = os.path.join(DATA_FOLDER, \"youtube_faiss_index\")\n",
    "VIDEO_LISTS_PATH = os.path.join(DATA_FOLDER, \"video_lists.json\")\n",
    "VIDEO_SUMMARIES_PATH = os.path.join(DATA_FOLDER, \"video_summaries.json\")\n",
    "ALL_VIDEOS_METADATA_PATH = os.path.join(DATA_FOLDER, \"all_videos_metadata.json\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(FAISS_INDEX_PATH), exist_ok=True)\n",
    "\n",
    "# Create a dictionary of paths to pass to init_mcp_tools\n",
    "data_paths = {\n",
    "    'DATA_PATH': DATA_PATH,\n",
    "    'FAISS_INDEX_PATH': FAISS_INDEX_PATH,\n",
    "    'VIDEO_LISTS_PATH': VIDEO_LISTS_PATH,\n",
    "    'VIDEO_SUMMARIES_PATH': VIDEO_SUMMARIES_PATH,\n",
    "    'ALL_VIDEOS_METADATA_PATH': ALL_VIDEOS_METADATA_PATH\n",
    "}\n",
    "\n",
    "print(f\"Data will be stored in: {DATA_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mk/Work/Agent_learning/data\n"
     ]
    }
   ],
   "source": [
    "print(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the MCP Tools\n",
    "\n",
    "Here we import the main functionality from the YouTube Transcript Knowledge Base project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MCP tools initialized successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Try importing as a package\n",
    "    from youtube_knowledgebase_mcp.mcp_tools import init_mcp_tools\n",
    "    from youtube_knowledgebase_mcp.data_management import initialize_data_files\n",
    "except ImportError:\n",
    "    # If package import fails, try importing from local files\n",
    "    print(\"Importing from local files instead of packages\")\n",
    "    \n",
    "    # This requires the project files to be in the same directory as this notebook\n",
    "    from importlib.machinery import SourceFileLoader\n",
    "    \n",
    "    # Load necessary modules from files\n",
    "    data_management = SourceFileLoader(\"data_management\", \"./data_management.py\").load_module()\n",
    "    mcp_tools = SourceFileLoader(\"mcp_tools\", \"./mcp_tools.py\").load_module()\n",
    "    \n",
    "    # Get required functions\n",
    "    init_mcp_tools = mcp_tools.init_mcp_tools\n",
    "    initialize_data_files = data_management.initialize_data_files\n",
    "\n",
    "# Initialize data files\n",
    "initialize_data_files(data_paths)\n",
    "\n",
    "# Initialize MCP tools\n",
    "init_mcp_tools(data_paths)\n",
    "\n",
    "print(\"✅ MCP tools initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tools for Direct Use\n",
    "\n",
    "Now we'll import the specific tools we need for our demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tools imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import all the tools we'll use in this demo\n",
    "try:\n",
    "    from youtube_knowledgebase_mcp.mcp_tools import (\n",
    "        process_youtube_video,\n",
    "        youtube_transcript_query_tool,\n",
    "        check_knowledge_base_status,\n",
    "        create_video_list,\n",
    "        add_video_to_list,\n",
    "        get_video_lists,\n",
    "        add_video_summary,\n",
    "        get_video_summary,\n",
    "        get_all_videos_info,\n",
    "        get_video_info,\n",
    "        filter_videos\n",
    "    )\n",
    "except ImportError:\n",
    "    # If package import fails, get functions from the module loaded above\n",
    "    process_youtube_video = mcp_tools.process_youtube_video\n",
    "    youtube_transcript_query_tool = mcp_tools.youtube_transcript_query_tool\n",
    "    check_knowledge_base_status = mcp_tools.check_knowledge_base_status\n",
    "    create_video_list = mcp_tools.create_video_list\n",
    "    add_video_to_list = mcp_tools.add_video_to_list\n",
    "    get_video_lists = mcp_tools.get_video_lists\n",
    "    add_video_summary = mcp_tools.add_video_summary\n",
    "    get_video_summary = mcp_tools.get_video_summary\n",
    "    get_all_videos_info = mcp_tools.get_all_videos_info\n",
    "    get_video_info = mcp_tools.get_video_info\n",
    "    filter_videos = mcp_tools.filter_videos\n",
    "\n",
    "print(\"✅ All tools imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check Knowledge Base Status\n",
    "\n",
    "First, let's check the current status of our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing FAISS index from /Users/mk/Work/Agent_learning/data/youtube_faiss_index\n",
      "Knowledge base location: /Users/mk/Work/Agent_learning/data/youtube_faiss_index\n",
      "Index size: Unknown (FAISS doesn't expose document count directly)\n",
      "Number of processed videos: 1\n",
      "Processed video IDs: CDjjaTALI68\n"
     ]
    }
   ],
   "source": [
    "status = check_knowledge_base_status()\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process a YouTube Video\n",
    "\n",
    "Now, let's process a YouTube video and add it to our knowledge base. Replace the URL with any YouTube video you'd like to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an educational YouTube video to process (replace with any video URL)\n",
    "video_url = \"https://www.youtube.com/watch?v=CDjjaTALI68\"  # Example: Understanding MCP From Scratch\n",
    "\n",
    "print(f\"Processing video: {video_url}\\n\")\n",
    "result = process_youtube_video(video_url)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query the Knowledge Base\n",
    "\n",
    "Now that we have a video in our knowledge base, let's query it to find specific information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# If you processed \"Study Less Study Smart\", a good query might be:\n",
    "query = \"Can you tell what is MCP based on the video?\"\n",
    "\n",
    "# You can modify this query for your specific video\n",
    "print(f\"Querying: '{query}'\\n\")\n",
    "results = youtube_transcript_query_tool(query)\n",
    "print(results) # raw results for FAISS retrieval\n",
    "# Process the query results using langchain_openai to get a more structured answer\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Format a prompt with the results to get a concise answer\n",
    "prompt = f\"\"\"\n",
    "Based on the transcript segments from the video, please provide a clear explanation of what MCP is.\n",
    "Here are the relevant transcript segments:\n",
    "{results}\n",
    "\n",
    "Please summarize what MCP is according to this video in a concise paragraph.\n",
    "\"\"\"\n",
    "\n",
    "# Get a structured answer\n",
    "structured_answer = llm.invoke(prompt)\n",
    "print(\"\\n=== Structured Answer ===\")\n",
    "print(structured_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing FAISS index from /Users/mk/Work/Agent_learning/data/youtube_faiss_index\n",
      "Question: Based on the video transcript, can you explain what MCP is?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/d6ptm61x6k7fqt_phjr3b5p80000gn/T/ipykernel_10677/1806714648.py:24: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/17/25 10:36:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/embeddings</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 </span> <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">OK\"</span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/17/25 10:36:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/embeddings\u001b[0m \u001b[32m\"HTTP/1.1 200 \u001b[0m \u001b]8;id=597899;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=65729;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mOK\"\u001b[0m                                                                    \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/17/25 10:36:44] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/17/25 10:36:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=460473;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=978390;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the video transcript, MCP (Model Control Protocol) is a standard protocol that provides a convenient interface to bind tools directly to various applications like IDEs and CLA desktop apps. It allows for communication between clients, applications, and resources like raw docs, with customizable communication. Essentially, MCP enables the integration of tools and context into different applications, making it simpler to connect and utilize various software tools efficiently.\n",
      "\n",
      "Source Documents:\n",
      "Document 1: Video 'Understanding MCP From Scratch' (ID: CDjjaTALI68) at 00:00:00.080\n",
      "Document 2: Video 'Understanding MCP From Scratch' (ID: CDjjaTALI68) at 00:00:00.080\n",
      "Document 3: Video 'Understanding MCP From Scratch' (ID: CDjjaTALI68) at 00:00:01.520\n",
      "Document 4: Video 'Understanding MCP From Scratch' (ID: CDjjaTALI68) at 00:00:01.520\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from youtube_knowledgebase_mcp.vector_store import get_or_create_faiss_index\n",
    "\n",
    "\n",
    "vectorstore = get_or_create_faiss_index(FAISS_INDEX_PATH)\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "def ask_llm(question):\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    result = qa_chain({\"query\": question})\n",
    "    \n",
    "    # Print the LLM's answer\n",
    "    print(\"Answer:\")\n",
    "    print(result[\"result\"])\n",
    "    \n",
    "    # Print the source documents used\n",
    "    print(\"\\nSource Documents:\")\n",
    "    for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "        video_id = doc.metadata.get(\"video_id\", \"unknown\")\n",
    "        title = doc.metadata.get(\"title\", \"Unknown Title\")\n",
    "        start_time = doc.metadata.get(\"start_time\", \"00:00:00\")\n",
    "        print(f\"Document {i}: Video '{title}' (ID: {video_id}) at {start_time}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Ask a question about the content we just added to the knowledge base\n",
    "llm_query = \"Based on the video transcript, can you explain what MCP is?\"\n",
    "llm_result = ask_llm(llm_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Function to ask questions about the knowledge base\\n\",\n",
    "    \"def ask_llm(question):\\n\",\n",
    "    \"    print(f\\\"Question: {question}\\\\n\\\")\\n\",\n",
    "    \"    result = qa_chain({\\\"query\\\": question})\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Print the LLM's answer\\n\",\n",
    "    \"    print(\\\"Answer:\\\")\\n\",\n",
    "    \"    print(result[\\\"result\\\"])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Print the source documents used\\n\",\n",
    "    \"    print(\\\"\\\\nSource Documents:\\\")\\n\",\n",
    "    \"    for i, doc in enumerate(result[\\\"source_documents\\\"], 1):\\n\",\n",
    "    \"        video_id = doc.metadata.get(\\\"video_id\\\", \\\"unknown\\\")\\n\",\n",
    "    \"        title = doc.metadata.get(\\\"title\\\", \\\"Unknown Title\\\")\\n\",\n",
    "    \"        start_time = doc.metadata.get(\\\"start_time\\\", \\\"00:00:00\\\")\\n\",\n",
    "    \"        print(f\\\"Document {i}: Video '{title}' (ID: {video_id}) at {start_time}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return result\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Ask a question about the content we just added to the knowledge base\\n\",\n",
    "    \"llm_query = \\\"What are the most effective study techniques mentioned in the video, and why do they work?\\\"\\n\",\n",
    "    \"llm_result = ask_llm(llm_query)\"\n",
    "   ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Video Information\n",
    "\n",
    "Let's examine the metadata for the video we just processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to extract the video ID from the result\n",
    "# This is a simple way to do it from the previous processing result\n",
    "import re\n",
    "\n",
    "# Extract video ID from the result or use a known ID\n",
    "video_id_match = re.search(r'ID: ([\\w-]+)', result)\n",
    "if video_id_match:\n",
    "    video_id = video_id_match.group(1)\n",
    "    print(f\"Found video ID: {video_id}\\n\")\n",
    "else:\n",
    "    # Fallback in case regex didn't work\n",
    "    video_id = \"zduSFxRajkE\"  # Replace with the actual video ID if known\n",
    "    print(f\"Using default video ID: {video_id}\\n\")\n",
    "\n",
    "# Get detailed information about the video\n",
    "video_info = get_video_info(video_id)\n",
    "print(video_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a Video List and Add the Video\n",
    "\n",
    "Let's organize our videos by creating a themed list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list for educational videos\n",
    "list_name = \"educational-videos\"\n",
    "list_description = \"Videos about learning, education, and study techniques\"\n",
    "\n",
    "create_result = create_video_list(list_name, list_description)\n",
    "print(create_result)\n",
    "\n",
    "# Add our video to the list\n",
    "add_result = add_video_to_list(video_id, list_name)\n",
    "print(add_result)\n",
    "\n",
    "# View all lists\n",
    "lists = get_video_lists()\n",
    "print(\"\\nCurrent video lists:\")\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add a Custom Summary\n",
    "\n",
    "Let's add our own summary to the video to enhance searchability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary for the video\n",
    "summary = \"\"\"\n",
    "This video is a comprehensive introduction to MCP (Model Context Protocol) presented by Lan from LangChain. \n",
    "The 12-minute tutorial takes a hands-on approach to explaining what MCP is and how to implement it from scratch.\n",
    "\"\"\"\n",
    "\n",
    "# Add the summary to the video\n",
    "summary_result = add_video_summary(video_id, summary)\n",
    "print(summary_result)\n",
    "\n",
    "# Retrieve the summary to verify\n",
    "get_summary_result = get_video_summary(video_id)\n",
    "print(\"\\nRetrieved summary:\")\n",
    "print(get_summary_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process Another Video (Optional)\n",
    "\n",
    "To build a more useful knowledge base, let's add another video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to process another video\n",
    "\n",
    "# video_url2 = \"https://www.youtube.com/watch?v=D7_ipDqhtwk\"  # Example: How We Build Effective Agents: Barry Zhang, Anthropic\n",
    "# print(f\"Processing second video: {video_url2}\\n\")\n",
    "# result2 = process_youtube_video(video_url2)\n",
    "# print(result2)\n",
    "\n",
    "# # Extract video ID for the second video\n",
    "# video_id2_match = re.search(r'ID: ([\\w-]+)', result2)\n",
    "# if video_id2_match:\n",
    "#     video_id2 = video_id2_match.group(1)\n",
    "#     print(f\"\\nAdding video ID: {video_id2} to educational-videos list\")\n",
    "#     add_video_to_list(video_id2, list_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Get All Videos Information\n",
    "\n",
    "Finally, let's get comprehensive information about all videos in our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos = get_all_videos_info()\n",
    "print(\"All videos in knowledge base:\")\n",
    "print(all_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the main functionality of the YouTube Transcript Knowledge Base:\n",
    "\n",
    "1. Processing YouTube videos to extract transcripts\n",
    "2. Querying the knowledge base for specific information\n",
    "3. Getting detailed information about videos\n",
    "4. Organizing videos into lists\n",
    "5. Adding custom summaries\n",
    "\n",
    "\n",
    "You can continue building your knowledge base by:\n",
    "- Processing more videos on topics you're interested in\n",
    "- Creating more specific lists to organize your videos\n",
    "- Adding detailed summaries to improve searchability\n",
    "- Running increasingly specific queries to find exactly the information you need\n",
    "\n",
    "This system helps you retain and retrieve valuable information from videos without having to rewatch them completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
