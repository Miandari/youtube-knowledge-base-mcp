{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Transcript Knowledge Base - Demo\n",
    "\n",
    "This notebook demonstrates the key functionality of the YouTube Transcript Knowledge Base project. It allows you to process YouTube videos, build a searchable knowledge base from their transcripts, organize videos into lists, and query the knowledge base for specific information.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, ensure you have the required dependencies installed and your OpenAI API key configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ OPENAI_API_KEY not found in environment variables.\n",
      "Please create a .env file with your OpenAI API key or set it manually below:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import dotenv\n",
    "os.environ.clear()\n",
    "# Load environment variables from .env file (containing your OPENAI_API_KEY)\n",
    "# dotenv.load_dotenv()\n",
    "\n",
    "# Verify OpenAI API key is available\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    print(\"⚠️ OPENAI_API_KEY not found in environment variables.\")\n",
    "    print(\"Please create a .env file with your OpenAI API key or set it manually below:\")\n",
    "    # Uncomment and replace with your key if needed\n",
    "    # os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
    "else:\n",
    "    print(\"✅ OpenAI API key found in environment variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data Paths\n",
    "\n",
    "Set up paths for data storage and initialize the MCP tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be stored in: /Users/mk/Work/Agent_learning/data\n"
     ]
    }
   ],
   "source": [
    "# Define paths similar to main.py\n",
    "BASE_PATH = os.path.dirname(os.path.abspath(\".\"))\n",
    "DATA_FOLDER = os.path.join(BASE_PATH, \"data\")\n",
    "DATA_PATH = os.path.join(DATA_FOLDER, \"processed_data\")\n",
    "FAISS_INDEX_PATH = os.path.join(DATA_FOLDER, \"youtube_faiss_index\")\n",
    "VIDEO_LISTS_PATH = os.path.join(DATA_FOLDER, \"video_lists.json\")\n",
    "VIDEO_SUMMARIES_PATH = os.path.join(DATA_FOLDER, \"video_summaries.json\")\n",
    "ALL_VIDEOS_METADATA_PATH = os.path.join(DATA_FOLDER, \"all_videos_metadata.json\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(FAISS_INDEX_PATH), exist_ok=True)\n",
    "\n",
    "# Create a dictionary of paths to pass to init_mcp_tools\n",
    "data_paths = {\n",
    "    'DATA_PATH': DATA_PATH,\n",
    "    'FAISS_INDEX_PATH': FAISS_INDEX_PATH,\n",
    "    'VIDEO_LISTS_PATH': VIDEO_LISTS_PATH,\n",
    "    'VIDEO_SUMMARIES_PATH': VIDEO_SUMMARIES_PATH,\n",
    "    'ALL_VIDEOS_METADATA_PATH': ALL_VIDEOS_METADATA_PATH\n",
    "}\n",
    "\n",
    "print(f\"Data will be stored in: {DATA_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mk/Work/Agent_learning/data\n"
     ]
    }
   ],
   "source": [
    "print(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the MCP Tools\n",
    "\n",
    "Here we import the main functionality from the YouTube Transcript Knowledge Base project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MCP tools initialized successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Try importing as a package\n",
    "    from youtube_knowledgebase_mcp.mcp_tools import init_mcp_tools\n",
    "    from youtube_knowledgebase_mcp.data_management import initialize_data_files\n",
    "except ImportError:\n",
    "    # If package import fails, try importing from local files\n",
    "    print(\"Importing from local files instead of packages\")\n",
    "    \n",
    "    # This requires the project files to be in the same directory as this notebook\n",
    "    from importlib.machinery import SourceFileLoader\n",
    "    \n",
    "    # Load necessary modules from files\n",
    "    data_management = SourceFileLoader(\"data_management\", \"./data_management.py\").load_module()\n",
    "    mcp_tools = SourceFileLoader(\"mcp_tools\", \"./mcp_tools.py\").load_module()\n",
    "    \n",
    "    # Get required functions\n",
    "    init_mcp_tools = mcp_tools.init_mcp_tools\n",
    "    initialize_data_files = data_management.initialize_data_files\n",
    "\n",
    "# Initialize data files\n",
    "initialize_data_files(data_paths)\n",
    "\n",
    "# Initialize MCP tools\n",
    "init_mcp_tools(data_paths)\n",
    "\n",
    "print(\"✅ MCP tools initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tools for Direct Use\n",
    "\n",
    "Now we'll import the specific tools we need for our demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tools imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import all the tools we'll use in this demo\n",
    "try:\n",
    "    from youtube_knowledgebase_mcp.mcp_tools import (\n",
    "        process_youtube_video,\n",
    "        youtube_transcript_query_tool,\n",
    "        check_knowledge_base_status,\n",
    "        create_video_list,\n",
    "        add_video_to_list,\n",
    "        get_video_lists,\n",
    "        add_video_summary,\n",
    "        get_video_summary,\n",
    "        get_all_videos_info,\n",
    "        get_video_info,\n",
    "        filter_videos\n",
    "    )\n",
    "except ImportError:\n",
    "    # If package import fails, get functions from the module loaded above\n",
    "    process_youtube_video = mcp_tools.process_youtube_video\n",
    "    youtube_transcript_query_tool = mcp_tools.youtube_transcript_query_tool\n",
    "    check_knowledge_base_status = mcp_tools.check_knowledge_base_status\n",
    "    create_video_list = mcp_tools.create_video_list\n",
    "    add_video_to_list = mcp_tools.add_video_to_list\n",
    "    get_video_lists = mcp_tools.get_video_lists\n",
    "    add_video_summary = mcp_tools.add_video_summary\n",
    "    get_video_summary = mcp_tools.get_video_summary\n",
    "    get_all_videos_info = mcp_tools.get_all_videos_info\n",
    "    get_video_info = mcp_tools.get_video_info\n",
    "    filter_videos = mcp_tools.filter_videos\n",
    "\n",
    "print(\"✅ All tools imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check Knowledge Base Status\n",
    "\n",
    "First, let's check the current status of our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base doesn't exist yet. Add transcripts first.\n"
     ]
    }
   ],
   "source": [
    "status = check_knowledge_base_status()\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process a YouTube Video\n",
    "\n",
    "Now, let's process a YouTube video and add it to our knowledge base. Replace the URL with any YouTube video you'd like to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: https://www.youtube.com/watch?v=ESfA3PXDKqM\n",
      "\n",
      "Getting metadata for: https://www.youtube.com/watch?v=ESfA3PXDKqM\n",
      "Processing video: 'Hearthstone But Your Deck is Random Legendaries'\n",
      "Extracting transcript from YouTube\n",
      "Extracted video ID: ESfA3PXDKqM\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=ESfA3PXDKqM\n",
      "[youtube] ESfA3PXDKqM: Downloading webpage\n",
      "[youtube] ESfA3PXDKqM: Downloading tv client config\n",
      "[youtube] ESfA3PXDKqM: Downloading player 9a279502-main\n",
      "[youtube] ESfA3PXDKqM: Downloading tv player API JSON\n",
      "[youtube] ESfA3PXDKqM: Downloading ios player API JSON\n",
      "[youtube] ESfA3PXDKqM: Downloading m3u8 information\n",
      "[info] ESfA3PXDKqM: Downloading subtitles: en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ffmpeg not found. The downloaded format may not be the best available. Installing ffmpeg is strongly recommended: https://github.com/yt-dlp/yt-dlp#dependencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] ESfA3PXDKqM: Downloading 1 format(s): 18\n",
      "[info] Writing video subtitles to: /var/folders/c9/d6ptm61x6k7fqt_phjr3b5p80000gn/T/tmpqri7dsr_/ESfA3PXDKqM.en.vtt\n",
      "[download] Destination: /var/folders/c9/d6ptm61x6k7fqt_phjr3b5p80000gn/T/tmpqri7dsr_/ESfA3PXDKqM.en.vtt\n",
      "[download] 100% of  151.90KiB in 00:00:00 at 1.69MiB/s\n",
      "Video info extracted: Hearthstone But Your Deck is Random Legendaries\n",
      "Found subtitle files: ['ESfA3PXDKqM.en.vtt']\n",
      "Using manual subtitle: ESfA3PXDKqM.en.vtt\n",
      "Successfully extracted transcript for video ID: ESfA3PXDKqM\n",
      "Processing transcript content...\n",
      "Saved processed transcript data to /Users/mk/Work/Agent_learning/data/processed_data/ESfA3PXDKqM_processed.json\n",
      "Saved video metadata to centralized storage\n",
      "Creating semantic chunks and updating knowledge base...\n",
      "Trying Ollama embeddings...\n",
      "Cannot connect to Ollama server: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x115b6a000>: Failed to establish a new connection: [Errno 61] Connection refused')). Is Ollama installed and running?\n",
      "Error initializing Ollama embeddings: Cannot connect to Ollama server: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x115b6a000>: Failed to establish a new connection: [Errno 61] Connection refused')). Run 'ollama serve' to start the server.\n",
      "Falling back to HuggingFace embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mk/Work/Agent_learning/YouTube_MCP/youtube_knowledgebase_mcp/vector_store.py:91: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  return HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/21/25 02:14:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> PyTorch version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.6</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> available.                                          <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/datasets/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/datasets/config.py#54\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/21/25 02:14:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m PyTorch version \u001b[1;36m2.6\u001b[0m.\u001b[1;36m0\u001b[0m available.                                          \u001b]8;id=625298;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/datasets/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=734719;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/datasets/config.py#54\u001b\\\u001b[2m54\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/21/25 02:14:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Use pytorch device_name: mps                                <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py#211\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">211</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/21/25 02:14:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Use pytorch device_name: mps                                \u001b]8;id=931607;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=750470;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py#211\u001b\\\u001b[2m211\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Load pretrained SentenceTransformer: all-MiniLM-L6-v2       <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py#219\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Load pretrained SentenceTransformer: all-MiniLM-L6-v2       \u001b]8;id=407945;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=824872;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py#219\u001b\\\u001b[2m219\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a46aca51204efca2900d16cc65166f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a93d51876bd49afbea35b9e387da1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2693e4289c34333ade81c15c40c0ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e529fb6f058f45728d4753c94a6273d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13985818131146f99f7ada2cbc2a3d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/21/25 02:14:29] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Xet Storage is enabled for this repo, but the <span style=\"color: #008000; text-decoration-color: #008000\">'hf_xet'</span> package   <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">file_download.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py#1670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1670</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         is not installed. Falling back to regular HTTP download. For     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         better performance, install the package with: `pip install       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         huggingface_hub<span style=\"font-weight: bold\">[</span>hf_xet<span style=\"font-weight: bold\">]</span>` or `pip install hf_xet`                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/21/25 02:14:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Xet Storage is enabled for this repo, but the \u001b[32m'hf_xet'\u001b[0m package   \u001b]8;id=542958;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\u001b\\\u001b[2mfile_download.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=815057;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py#1670\u001b\\\u001b[2m1670\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         is not installed. Falling back to regular HTTP download. For     \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         better performance, install the package with: `pip install       \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         huggingface_hub\u001b[1m[\u001b[0mhf_xet\u001b[1m]\u001b[0m` or `pip install hf_xet`                 \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0b2f76232d49d4931038d84fc0afba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d274be14bcf54650b268041c151a3a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c12ac1fecb34d009bdaf11c165a8a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38de1313898e42368b8fdd1c6b6695dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bf530c46ee4184b7b935a1e745048f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4f8337951549f7a535624977599c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new FAISS index with 50 documents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/21/25 02:14:38] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading faiss.                                                           <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/loader.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">loader.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/loader.py#148\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/21/25 02:14:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading faiss.                                                           \u001b]8;id=503070;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/loader.py\u001b\\\u001b[2mloader.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=977177;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/loader.py#148\u001b\\\u001b[2m148\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Successfully loaded faiss.                                               <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/loader.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">loader.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/loader.py#150\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">150</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Successfully loaded faiss.                                               \u001b]8;id=588728;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/loader.py\u001b\\\u001b[2mloader.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=683433;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/loader.py#150\u001b\\\u001b[2m150\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Failed to load GPU Faiss: name <span style=\"color: #008000; text-decoration-color: #008000\">'GpuIndexIVFFlat'</span> is not defined. Will  <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/__init__.py#173\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         not load constructor refs for GPU indexes.                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Failed to load GPU Faiss: name \u001b[32m'GpuIndexIVFFlat'\u001b[0m is not defined. Will  \u001b]8;id=869256;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=496530;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/faiss/__init__.py#173\u001b\\\u001b[2m173\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         not load constructor refs for GPU indexes.                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed YouTube video 'Hearthstone But Your Deck is Random Legendaries' (ID: ESfA3PXDKqM) with 50 semantic chunks\n",
      "Successfully processed YouTube video 'Hearthstone But Your Deck is Random Legendaries' (ID: ESfA3PXDKqM) with 50 semantic chunks\n"
     ]
    }
   ],
   "source": [
    "# Choose an educational YouTube video to process (replace with any video URL)\n",
    "video_url = \"https://www.youtube.com/watch?v=CDjjaTALI68\"  # Example: Understanding MCP From Scratch\n",
    "\n",
    "print(f\"Processing video: {video_url}\\n\")\n",
    "result = process_youtube_video(video_url)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query the Knowledge Base\n",
    "\n",
    "Now that we have a video in our knowledge base, let's query it to find specific information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# If you processed Understanding MCP From Scratch, a good query might be:\n",
    "query = \"Can you tell what is MCP based on the video?\"\n",
    "\n",
    "# You can modify this query for your specific video\n",
    "print(f\"Querying: '{query}'\\n\")\n",
    "results = youtube_transcript_query_tool(query)\n",
    "print(results) # raw results for FAISS retrieval\n",
    "# Process the query results using langchain_openai to get a more structured answer\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Format a prompt with the results to get a concise answer\n",
    "prompt = f\"\"\"\n",
    "Based on the transcript segments from the video, please provide a clear explanation of what MCP is.\n",
    "Here are the relevant transcript segments:\n",
    "{results}\n",
    "\n",
    "Please summarize what MCP is according to this video in a concise paragraph.\n",
    "\"\"\"\n",
    "\n",
    "# Get a structured answer\n",
    "structured_answer = llm.invoke(prompt)\n",
    "print(\"\\n=== Structured Answer ===\")\n",
    "print(structured_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing FAISS index from /Users/mk/Work/Agent_learning/data/youtube_faiss_index\n",
      "Question: Based on the video transcript, can you explain what MCP is?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/d6ptm61x6k7fqt_phjr3b5p80000gn/T/ipykernel_10677/1806714648.py:24: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/17/25 10:36:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/embeddings</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 </span> <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">OK\"</span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/17/25 10:36:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/embeddings\u001b[0m \u001b[32m\"HTTP/1.1 200 \u001b[0m \u001b]8;id=597899;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=65729;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mOK\"\u001b[0m                                                                    \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/17/25 10:36:44] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/17/25 10:36:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=460473;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=978390;file:///Users/mk/Work/Agent_learning/YouTube_MCP/.venv/lib/python3.12/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the video transcript, MCP (Model Control Protocol) is a standard protocol that provides a convenient interface to bind tools directly to various applications like IDEs and CLA desktop apps. It allows for communication between clients, applications, and resources like raw docs, with customizable communication. Essentially, MCP enables the integration of tools and context into different applications, making it simpler to connect and utilize various software tools efficiently.\n",
      "\n",
      "Source Documents:\n",
      "Document 1: Video 'Understanding MCP From Scratch' (ID: CDjjaTALI68) at 00:00:00.080\n",
      "Document 2: Video 'Understanding MCP From Scratch' (ID: CDjjaTALI68) at 00:00:00.080\n",
      "Document 3: Video 'Understanding MCP From Scratch' (ID: CDjjaTALI68) at 00:00:01.520\n",
      "Document 4: Video 'Understanding MCP From Scratch' (ID: CDjjaTALI68) at 00:00:01.520\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from youtube_knowledgebase_mcp.vector_store import get_or_create_faiss_index\n",
    "\n",
    "\n",
    "vectorstore = get_or_create_faiss_index(FAISS_INDEX_PATH)\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "def ask_llm(question):\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    result = qa_chain({\"query\": question})\n",
    "    \n",
    "    # Print the LLM's answer\n",
    "    print(\"Answer:\")\n",
    "    print(result[\"result\"])\n",
    "    \n",
    "    # Print the source documents used\n",
    "    print(\"\\nSource Documents:\")\n",
    "    for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "        video_id = doc.metadata.get(\"video_id\", \"unknown\")\n",
    "        title = doc.metadata.get(\"title\", \"Unknown Title\")\n",
    "        start_time = doc.metadata.get(\"start_time\", \"00:00:00\")\n",
    "        print(f\"Document {i}: Video '{title}' (ID: {video_id}) at {start_time}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Ask a question about the content we just added to the knowledge base\n",
    "llm_query = \"Based on the video transcript, can you explain what MCP is?\"\n",
    "llm_result = ask_llm(llm_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Video Information\n",
    "\n",
    "Let's examine the metadata for the video we just processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to extract the video ID from the result\n",
    "# This is a simple way to do it from the previous processing result\n",
    "import re\n",
    "\n",
    "# Extract video ID from the result or use a known ID\n",
    "video_id_match = re.search(r'ID: ([\\w-]+)', result)\n",
    "if video_id_match:\n",
    "    video_id = video_id_match.group(1)\n",
    "    print(f\"Found video ID: {video_id}\\n\")\n",
    "else:\n",
    "    # Fallback in case regex didn't work\n",
    "    video_id = \"zduSFxRajkE\"  # Replace with the actual video ID if known\n",
    "    print(f\"Using default video ID: {video_id}\\n\")\n",
    "\n",
    "# Get detailed information about the video\n",
    "video_info = get_video_info(video_id)\n",
    "print(video_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a Video List and Add the Video\n",
    "\n",
    "Let's organize our videos by creating a themed list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list for educational videos\n",
    "list_name = \"educational-videos\"\n",
    "list_description = \"Videos about learning, education, and study techniques\"\n",
    "\n",
    "create_result = create_video_list(list_name, list_description)\n",
    "print(create_result)\n",
    "\n",
    "# Add our video to the list\n",
    "add_result = add_video_to_list(video_id, list_name)\n",
    "print(add_result)\n",
    "\n",
    "# View all lists\n",
    "lists = get_video_lists()\n",
    "print(\"\\nCurrent video lists:\")\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add a Custom Summary\n",
    "\n",
    "Let's add our own summary to the video to enhance searchability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary for the video\n",
    "summary = \"\"\"\n",
    "This video is a comprehensive introduction to MCP (Model Context Protocol) presented by Lan from LangChain. \n",
    "The 12-minute tutorial takes a hands-on approach to explaining what MCP is and how to implement it from scratch.\n",
    "\"\"\"\n",
    "\n",
    "# Add the summary to the video\n",
    "summary_result = add_video_summary(video_id, summary)\n",
    "print(summary_result)\n",
    "\n",
    "# Retrieve the summary to verify\n",
    "get_summary_result = get_video_summary(video_id)\n",
    "print(\"\\nRetrieved summary:\")\n",
    "print(get_summary_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process Another Video (Optional)\n",
    "\n",
    "To build a more useful knowledge base, let's add another video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to process another video\n",
    "\n",
    "# video_url2 = \"https://www.youtube.com/watch?v=D7_ipDqhtwk\"  # Example: How We Build Effective Agents: Barry Zhang, Anthropic\n",
    "# print(f\"Processing second video: {video_url2}\\n\")\n",
    "# result2 = process_youtube_video(video_url2)\n",
    "# print(result2)\n",
    "\n",
    "# # Extract video ID for the second video\n",
    "# video_id2_match = re.search(r'ID: ([\\w-]+)', result2)\n",
    "# if video_id2_match:\n",
    "#     video_id2 = video_id2_match.group(1)\n",
    "#     print(f\"\\nAdding video ID: {video_id2} to educational-videos list\")\n",
    "#     add_video_to_list(video_id2, list_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Get All Videos Information\n",
    "\n",
    "Finally, let's get comprehensive information about all videos in our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos = get_all_videos_info()\n",
    "print(\"All videos in knowledge base:\")\n",
    "print(all_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the main functionality of the YouTube Transcript Knowledge Base:\n",
    "\n",
    "1. Processing YouTube videos to extract transcripts\n",
    "2. Querying the knowledge base for specific information\n",
    "3. Getting detailed information about videos\n",
    "4. Organizing videos into lists\n",
    "5. Adding custom summaries\n",
    "\n",
    "\n",
    "You can continue building your knowledge base by:\n",
    "- Processing more videos on topics you're interested in\n",
    "- Creating more specific lists to organize your videos\n",
    "- Adding detailed summaries to improve searchability\n",
    "- Running increasingly specific queries to find exactly the information you need\n",
    "\n",
    "This system helps you retain and retrieve valuable information from videos without having to rewatch them completely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
